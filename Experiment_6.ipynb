{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Experiment 6: Architecture 2 with Weighted Objective Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# finding accuracy \n",
    "def accuracy_score(outputs, targets, batch_size):\n",
    "    out = output_to_guess(outputs, 0.5)\n",
    "    numCorrect = int(torch.sum(torch.sum((out == targets), dim=1)))\n",
    "    total = batch_size * 14\n",
    "    return numCorrect / total\n",
    "\n",
    "\n",
    "#helper function to convert a network output to a guess\n",
    "def output_to_guess(output, cutoff):\n",
    "    # create a temporary tensor to not override original\n",
    "    temp = output.clone()\n",
    "    temp[output >= 0.5] = 1\n",
    "    temp[output < 0.5] = 0\n",
    "    return temp\n",
    "\n",
    "# printing performce of model\n",
    "def printModelPerformance(performanceList):\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    bcr_list = []\n",
    "    for i in range(len(performanceList)):\n",
    "        ac, pre, re, bcr = printSingleStat(performanceList, i)\n",
    "        accuracy_list.append(ac)\n",
    "        precision_list.append(pre)\n",
    "        recall_list.append(re)\n",
    "        bcr_list.append(bcr)\n",
    "    print(\"Model Average Performece\")\n",
    "    print(\"Accuracy: \", round((sum(accuracy_list) / len(accuracy_list)), 3))\n",
    "    print(\"Precision: \", round((sum(precision_list) / len(precision_list)), 3))\n",
    "    print(\"Recall: \", round((sum(recall_list) / len(recall_list)), 3))\n",
    "    print(\"BCR: \", round((sum(bcr_list) / len(bcr_list)),3))\n",
    "    \n",
    "def printSingleStat(performanceList, index):\n",
    "    disease = test_loader.dataset.classes[index]\n",
    "    TP = p_r_list[index][\"TP\"]\n",
    "    FP = p_r_list[index][\"FP\"]\n",
    "    TN = p_r_list[index][\"TN\"]\n",
    "    FN = p_r_list[index][\"FN\"]\n",
    "    \n",
    "    Acc = (TN + TP) / (TP + TN + FP + FN)\n",
    "    Precision = (TP) / (FP + TP)\n",
    "    Recall = (TP) / (TP + FN)\n",
    "    BCR = (Precision + Recall) / 2\n",
    "    print(\"Disease: \", disease)\n",
    "    print(\"Accuracy: \", round(Acc,3))\n",
    "    print(\"Precision: \", round(Precision,3))\n",
    "    print(\"Recall: \", round(Recall,3))\n",
    "    print(\"BCR: \", round(BCR,3))\n",
    "    \n",
    "    return Acc, Precision, Recall, BCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n",
      "Model on CUDA? True\n"
     ]
    }
   ],
   "source": [
    "#TODO\n",
    "from architecture1_cnn import *\n",
    "from architecture1_cnn import arch1_cnn\n",
    "from copy import deepcopy\n",
    "\n",
    "# Setup: initialize the hyperparameters/variables\n",
    "num_epochs = 1           # Number of full passes through the dataset\n",
    "batch_size = 32        # Number of samples in each minibatch\n",
    "learning_rate = 0.0001  \n",
    "seed = np.random.seed(1) # Seed the random number generator for reproducibility\n",
    "p_val = 0.1              # Percent of the overall dataset to reserve for validation\n",
    "p_test = 0.2             # Percent of the overall dataset to reserve for testing\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((512,512)), transforms.ToTensor()])\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")\n",
    "\n",
    "# Setup the training, validation, and testing dataloaders\n",
    "train_loader, val_loader, test_loader = create_split_loaders(batch_size, seed, transform=transform, \n",
    "                                                             p_val=p_val, p_test=p_test,\n",
    "                                                             shuffle=True, show_sample=False, \n",
    "                                                             extras=extras)\n",
    "\n",
    "model = arch1_cnn()\n",
    "model = model.to(computing_device)\n",
    "print(\"Model on CUDA?\", next(model.parameters()).is_cuda)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8f78fa0fc722>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrunning_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mminibatch_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader timed out after {} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/datasets/home/16/516/u1singh/CNN-PA3/xray_dataloader.py\", line 102, in __getitem__\n",
      "    image = Image.open(image_path).convert(mode=str(self.color))\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/PIL/Image.py\", line 879, in convert\n",
      "    self.load()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "running_count = [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "count = 0\n",
    "for minibatch_count, (images, labels) in enumerate(val_loader, 0):\n",
    "    print(minibatch_count)\n",
    "    for row in labels.split(1):\n",
    "        running_count += row.numpy()[0]\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.4                inf  6.11111111  8.14285714 31.          9.66666667\n",
      "         inf 31.         20.33333333 63.                 inf         inf\n",
      " 31.         63.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "numPos = running_count\n",
    "numNeg = count - numPos\n",
    "print(numNeg / numPos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_BCE_Loss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Custom_BCE_Loss, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        #puts a range on the outputs to avoid a nan error\n",
    "        output = output.clamp(min=1e-7, max=1-1e-7)\n",
    "        #output = func.sigmoid(output)\n",
    "        #print(output)\n",
    "        target = target.float()\n",
    "        #print(target)\n",
    "        \n",
    "        #w_n = 1.0542549460062538\n",
    "        #w_p = 19.431499312242092\n",
    "        #w_p = 200\n",
    "        \n",
    "        w_n = torch.cuda.FloatTensor(np.array(numNeg) / (np.array(numPos) + np.array(numNeg)))\n",
    "        w_p = torch.cuda.FloatTensor(np.array(numPos) / (np.array(numPos) + np.array(numNeg)))\n",
    "        \n",
    "        \n",
    "        loss = (-1) * w_p *(target * torch.log(output)) -  ((1 - target) * w_n * torch.log(1 - output))\n",
    "        \n",
    "        return loss.sum()\n",
    "    \n",
    "criterion = Custom_BCE_Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, average minibatch 50 loss: 35.621\n",
      "accuracy 0.955580357142857\n",
      "Epoch 1, average minibatch 100 loss: 14.336\n",
      "accuracy 0.948705357142857\n"
     ]
    }
   ],
   "source": [
    "# Track the loss across training\n",
    "total_loss = []\n",
    "avg_minibatch_loss = []\n",
    "all_valid_loss = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "best_model = model\n",
    "\n",
    "# Begin training procedure\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    N = 50\n",
    "    Validation_N = 250\n",
    "    N_minibatch_loss = 0.0\n",
    "    N_minibatch_accuracy = 0.0\n",
    "\n",
    "    # Get the next minibatch of images, labels for training\n",
    "    for minibatch_count, (images, labels) in enumerate(train_loader, 0):\n",
    "        \n",
    "\n",
    "        # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "        images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "        \n",
    "        # Zero out the stored gradient (buffer) from the previous iteration\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform the forward pass through the network and compute the loss\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        accuracy = accuracy_score(outputs, labels, batch_size)\n",
    "        \n",
    "        # Automagically compute the gradients and backpropagate the loss through the network\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Add this iteration's loss to the total_loss\n",
    "        total_loss.append(loss.item())\n",
    "        N_minibatch_loss += loss\n",
    "        N_minibatch_accuracy += accuracy\n",
    "        \n",
    "            \n",
    "        if (minibatch_count % N == 0) & (minibatch_count > 0):    \n",
    "            \n",
    "            # Print the loss averaged over the last N mini-batches    \n",
    "            N_minibatch_loss /= N\n",
    "            N_minibatch_accuracy /= N\n",
    "            print('Epoch %d, average minibatch %d loss: %.3f' %\n",
    "                (epoch + 1, minibatch_count, N_minibatch_loss))\n",
    "            \n",
    "            # Add the averaged loss over N minibatches and reset the counter\n",
    "            avg_minibatch_loss.append(N_minibatch_loss)\n",
    "            print(\"accuracy\", N_minibatch_accuracy)\n",
    "            train_accuracies.append(N_minibatch_accuracy)\n",
    "            N_minibatch_loss = 0.0\n",
    "            N_minibatch_accuracy = 0.0\n",
    "            \n",
    "                \n",
    "    val_loss = 0\n",
    "    accuracy = 0\n",
    "    with torch.no_grad(): \n",
    "        for minibatch_count, (images, labels) in enumerate(val_loader, 0):\n",
    "            # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "            images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            val_loss += criterion(outputs, labels)\n",
    "            accuracy += accuracy_score(outputs, labels, batch_size)\n",
    "\n",
    "        avgLoss = val_loss / minibatch_count\n",
    "        valAccuracy = accuracy / minibatch_count\n",
    "\n",
    "        print(\"Val Loss\", avgLoss.item())\n",
    "        print(\"Accuracy\", valAccuracy)\n",
    "        #checks if model is best model so far\n",
    "        if (len(all_valid_loss) == 0):\n",
    "            model = deepcopy(model)\n",
    "        else:\n",
    "            if (avgLoss.item() < min(all_valid_loss)):\n",
    "                model = deepcopy(model)\n",
    "        all_valid_loss.append(avgLoss.item())\n",
    "        val_accuracies.append(valAccuracy)\n",
    "\n",
    "    print(\"Finished\", epoch + 1, \"epochs of training\")\n",
    "print(\"Training complete after\", epoch + 1, \"epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Accuracy plotting\n",
    "\n",
    "x1 = np.linspace(0,50,len(train_accuracies))\n",
    "x2 = np.linspace(0,50,len(val_accuracies))\n",
    "\n",
    "plt.plot(x1, train_accuracies, color = \"red\",label = \"Training Set Accuracy\")\n",
    "plt.plot(x2, val_accuracies, color = \"blue\",label = \"Validation Set Accuracy\")\n",
    "plt.xlabel(\"Number of MiniBatches (x50 each)\")\n",
    "plt.ylabel(\"Percentage Correct\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Function plotting\n",
    "\n",
    "x1 = np.linspace(0,50,len(train_accuracies))\n",
    "x2 = np.linspace(0,50,len(val_accuracies))\n",
    "\n",
    "plt.plot(x1, avg_minibatch_loss, color = \"red\",label = \"Training Set Accuracy\")\n",
    "plt.plot(x2, all_valid_loss, color = \"blue\",label = \"Validation Set Accuracy\")\n",
    "plt.xlabel(\"Number of MiniBatches (x50 each)\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer 1 Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = (best_model.conv1.weight.cpu().data.numpy()[3])[0]\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = (best_model.conv1.weight.cpu().data.numpy()[2])[0]\n",
    "plt.imshow(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer 3 Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = (best_model.conv3.weight.cpu().data.numpy()[3])[0]\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = (best_model.conv3.weight.cpu().data.numpy()[8])[0]\n",
    "plt.imshow(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer 5 Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (best_model.conv5.weight.cpu().data.numpy()[3])[0]\n",
    "plt.imshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = (best_model.conv5.weight.cpu().data.numpy()[0])[0]\n",
    "plt.imshow(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test based on best_model variable\n",
    "\n",
    "print(len(test_loader))\n",
    "\n",
    "p_r_list = []    #list of dictionaries, where each dictionary contains 'TP', 'FP', 'TN', 'FN'\n",
    "\n",
    "for i in range(14):\n",
    "    p_r_list.append({'TP': 0, 'FP': 0, 'TN': 0, 'FN': 0})\n",
    "\n",
    "c_matrix = []     # confusion matrix\n",
    "\n",
    "for i in range(14):\n",
    "    c_matrix.append([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "for minibatch_count, (images, labels) in enumerate(test_loader, 0):\n",
    "    \n",
    "    print(minibatch_count)\n",
    "    # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "    images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "    \n",
    "    outputs = model(images)\n",
    "    outputs = output_to_guess(outputs, 0.5)\n",
    "    with torch.no_grad():\n",
    "        for i in range(outputs.shape[0]):\n",
    "            out = outputs.split(1)[i].tolist()[0]    # convert the outputs from tensor object to a list\n",
    "            lab = labels.split(1)[i].tolist()[0]     # convert the labels from tensor object to a list\n",
    "\n",
    "            for j in range(14):\n",
    "                if out[j] == 1 and lab[j] == 1:\n",
    "                    p_r_list[j]['TP'] += 1\n",
    "                elif out[j] == 1 and lab[j] == 0:\n",
    "                    p_r_list[j]['FP'] += 1\n",
    "                elif out[j] == 0 and lab[j] == 0:\n",
    "                    p_r_list[j]['TN'] += 1\n",
    "                else:\n",
    "                    p_r_list[j]['FN'] += 1\n",
    "\n",
    "            for k in range(14):\n",
    "                if (out[k] == 1 and lab[k] == 1) or (out[k] == 1 and lab[k] == 1):     # if output == label, put a 1 at (k,k) and zeros for everything else in that row\n",
    "                    c_matrix[k][k] += 1\n",
    "                if out[k] == 1 and lab[k] == 0:   # if output = 1 and label = 0, evenly distribute the error amongst activated outputs (where out[k] == 1)\n",
    "                    sum_of_out = sum(out)\n",
    "                    for a in range(14):\n",
    "                        if out[a] == 1:\n",
    "                            c_matrix[k][a] += 1/sum_of_out\n",
    "                if out[k] == 0 and lab[k] == 1:   # if output = 0 and label = 1, put zeros for the row (it's not confused with other classes)\n",
    "                    continue\n",
    "\n",
    "for x in range(len(c_matrix)):\n",
    "    row_sum = sum(c_matrix[x])\n",
    "    if (row_sum != 0):\n",
    "        for y in range(14):\n",
    "            c_matrix[x][y] = c_matrix[x][y] / row_sum\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printModelPerformance(p_r_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print confusion matrix\n",
    "\n",
    "for i in c_matrix:\n",
    "    a = ['%.2f' % elem for elem in i]\n",
    "    print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
